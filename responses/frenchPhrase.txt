Bonjour et bienvenue à choisir la bonne} base de données pour les applications modernes dans le cadre de} notre série en ligne West Summit ajoutée} Je m'appelle William Wong et je suis} un architecte spécialisé en solutions de bases de données} Et aujourd'hui, je serai rejoint par Michael} Riccardi, qui est notre architecte spécialisé en solutions de développement} Aujourd'hui} Nous sommes Je suis vraiment heureuse d'être là pour} vous montrer comment des bases de données spécialement conçues peuvent} être utilisées pour améliorer l'échelle, les performances} et la disponibilité de vos applications pour notre} agenda vous présentera les} exigences des applications modernes} Nous examinerons ensuite les défis qui} sont résolus en utilisant } microservices et bases de données personnalisées} Avant de voir comment nous pouvons} choisir les bonnes bases de données} pour vos charges de travail particulières} Michael} Nous allons ensuite approfondir} où il modernisera une application, passant d'une pile de bases de données relationnelles monolithiques à une pile de bases de données relationnelles monolithiques à celle de} en utilisant des bases de données spécialement conçues et vous montrerons } les différences de performance et d'échelle} Commençons donc et examinons} les exigences de nos applications modernes} Et nous examinons d'abord les applications} que nous utilisons tous les jours, comme} notre covoiturage, nos médias, notre streaming, nos services bancaires, nos jeux} et les réseaux sociaux} Nous commençons à voir des modèles communs} Ces modèles Il pourrait s'agir de millions d'utilisateurs} accédant à nos applications dans différentes zones géographiques} Et ces mêmes utilisateurs s'attendent à des expériences instantanées} qui pourraient se résumer à des temps de réponse constants en millisecondes, voire en dessous de la milliseconde} Nos applications devront être mises à l'échelle} pour répondre aux demandes d'événements tels que} nos ventes flash ou } traitement de l'urine et} réduction de la taille} Nous ne sommes pas utilisés pour} minimiser les coûts} Il est prévu de capturer plus} de données au cours des trois prochaines années que} celles des 30 dernières années} Et cela nécessitera des outils spécialisés pour} traiter les pétaoctets} Sinon zéro octet de structure} et données non structurées} Si nous prenons un peu de temps maintenant et} réfléchissons aux modèles architecturaux de la plupart de ces applications basées sur le cloud, vous constaterez} qu'elles sont toutes des microservices} Cela signifie qu'elles sont hautement distribuées, lâchement} couplées et accessibles via un P} I} S} Alors, que signifie ce changement d'architecture} pour notre base de données sous-jacente Comme nos} applications sont maintenant découplées en services} Cela permet à chacun de ces services de} avoir sa propre base de données indépendante} Et cela nous apportera de nombreux avantages, par exemple, nous donnera la possibilité d'hyperdimensionner nos applications en tant que} chaque service et canal de base de données évolue indépendamment} }} Nous devrons peut-être adapter notre catalogue} et notre service de paiement à des centaines de milliers} de demandes simultanées sur une courte période} mais nos inscriptions d'utilisateurs peuvent ne pas augmenter au même degré} Un autre avantage est l'agilité supplémentaire} Puisque nous pouvons désormais innover plus rapidement}} différents composants} Nous pouvons rapidement tester et restaurer} de nouvelles versions et fonctionnalités à un niveau modulaire} sans nous occuper de toutes les dépendances couplées complexes qui sont liées aux monolithes} Un défi commercial courant consiste à rendre nos} applications plus disponibles et en découplant nos} bases de données, cela augmentera son } disponibilité globale} puisque nous n'avons plus de base de données monolithique} qui sert de point de discorde unique pour nos événements tels que} des déploiements de code ou des mises à niveau et des correctifs} Maintenant que nous comprenons les avantages} du découplage de nos données} T, pourquoi envisagerions-nous des bases de données spécialement conçues} pour notre {microservices} Nos développeurs veulent la bonne base de données pour} répondre aux besoins de nos applications modernes} comme nous l'avons décrit précédemment} Et franchement, cette approche unique consistant à utiliser une base de données relationnelle pour} tout, ne fonctionne tout simplement plus} Par exemple, nous pouvons avoir besoin d'une base de données} pour fournir une latence de l'ordre de la microseconde } temps de réponse afin que nous puissions afficher rapidement nos sites Web} ou pour fournir des temps de réponse cohérents pour} répondre aux demandes des utilisateurs d'un chirurgien} Et l'architecture relationnelle n'est pas la meilleure solution pour ces cas d'utilisation particuliers} En fait, ne pas utiliser la bonne} base de données entraînera généralement des problèmes de performance,} le manque d'évolutivité, le manque de flexibilité des développeurs} et une augmentation de nos coûts globaux} Donc, traditionnellement, lorsque je parle à mes} clients, un obstacle à l'adoption de ces objectifs} des bases de données créées avec des frais généraux opérationnels potentiels} Et cela comprenait des investissements dans du matériel initial} et des logiciels ou une expertise pour les rendre évolutifs, hautement disponibles et performants} Et c'est là qu'AWS entre en jeu} Nous proposerons le portefeuille le plus large et le plus complet} de plus de 15 bases de données spécialement conçues qui} peuvent prendre en charge les différents modèles de données en utilisant} des bases de données personnalisées et entièrement gérées} que nous avons créées de A à Z} les clients peuvent désormais économiser du temps et de l'argent,} améliorer les performances à grande échelle et innover plus rapidement} Nous avons créé des bases de données spécialement conçues pour correspondre} à tous les cas d'utilisation, comme la valeur clé relationnelle} les documents en mémoire, les séries chronologiques à colonnes larges} le registre et nos bases de données graphiques} Maintenant que nous comprenons le besoin} d'une conception spécifique bases de données, comment feriez-vous alors} pour sélectionner les bonnes bases de données} pour vos cas d'utilisation particuliers} Ce que j'aimerais dire aux gens, c'est} au lieu de regarder une liste de} 100 bases de données différentes, pourquoi ne pas commencer} par réfléchir à des catégories de bases de données communes} Maintenant, nous examinons rapidement les} catégories} Non seulement vous y trouverez cette base de données relationnelle familière sur la gauche, mais} vous verrez également d'autres bases de données, comme} notre base de données de documents Amazon qui est optimisée} pour stocker les données au format Jason} Et comme il s'agit d'une base de données sans suite,} cela nous donnera cette flexibilité en ce qui concerne} le changement des schémas d'applications mais cela va aussi} nous permettre d'interroger des documents en fonction de} n'importe quel attribut} Et c'est vraiment pratique pour notre} gestion de contenu ou applications mobiles ou une} base de données graphique comme amazon Neptune, qui alors} nous permet de travailler avec} des ensembles de données hautement connectés} Nous pouvons essayer de modéliser cela} dans un } une base de données avec des articulations compliquées} et des requêtes imbriquées (mais notre latence est de} augmentera à mesure que le nombre de nos} relations augmentera dans les bases de données graphiques} Cependant, cela nous permet de parcourir des millions} de relations en quelques secondes, ce qui est excellent} pour la détection des fraudes, les réseaux sociaux et nos} moteurs de recommandation} Eh bien enfin, comme une base de données de séries chronologiques} comme notre flux temporel Amazon, qui est {optimisé pour ingérer des milliards de séquences temporelles} de données par jour, tout en nous donnant} des fonctions basées sur le temps, telles que la corrélation} et l'interpolation, afin que nous puissions obtenir} de meilleures informations à partir de ces données} Et c'est idéal pour nos devops ou événements IoT} applications de suivi} Prenons le temps de plonger} un peu plus loin dans certaines catégories très courantes} que j'ai vues chez mes clients} Commençons par un modèle de données relationnel très familier, les données relationnelles sont hautement} structurées et les données sont divisées} en tableaux et les relations sont appliquées par} le système est composé de clés primaires et de référence} et de bons cas d'utilisation seront} les charges de travail pour lesquelles nous ne pouvons pas tout prédéfinir}} nos modèles d'accès à l'avance ou si} nous avions des applications nécessitant un référentiel élevé} une intégrité et une cohérence fortes} Comme pour nos systèmes de paiement en ligne} Une base de données cloud native que nous pourrions choisir } pour nos modèles relationnels est amazon} Arora} Arora est compatible à la fois avec ma suite} et Postgres et peut nous aider à améliorer} nos performances en fournissant jusqu'à cinq} fois plus de débit que celui de la version standard} Ma suite et trois fois plus que} celle de Postgres standard} Cela nous aidera à faire évoluer automatiquement les deux } ressources de calcul et de stockage et nous avons dessiné} Billy stocke nos données de six manières différentes} Trois zones de disponibilité} Et comme il s'agit d'un service géré,} il assurera l'automatisation des tâches telles que} le déploiement et le provisionnement, les correctifs et les mises à niveau réguliers,} les sauvegardes et nous fournira des fonctionnalités de sécurité telles que} le cryptage dans transit et repos} Une autre catégorie intéressante} Pour examiner nos bases de données de valeurs clés}} Les données sur les valeurs clés sont celles qui utilisent} cette méthode simple de stockage et de récupération des données et leur force réside} dans leur conception de partitionner fortement ou} de partager les données, puis de les stocker physiquement} en fonction de cette clé de partition} Cette conception lui permet de s'adapter horizontalement} à pratiquement n'importe quelle taille, tout en nous offrant} des temps de réponse constants, quelle que soit l'échelle.} Passons donc en revue un cas d'utilisation} pour un jeu en ligne qui doit} stocker les données de session d'un utilisateur et possède} un modèle d'accès défini via le gamer tag} pour récupérer ces données set} Comme il s'agit d'un jeu en ligne, nous voulons} garantir une expérience cohérente au joueur, qu'il y ait 10 ou même 100 000 utilisateurs} Si le jeu prend son envol dans ce cas d'utilisation particulier, nous utiliserons une base de données de valeurs clés} pour obtenir des temps de réponse cohérents,} quelle que soit la croissance du application} Une base de données spécialement conçue que nous pourrions choisir} pour nos bases de données clés est amazon} dynamodb} Elle est entièrement gérée et sans serveur, ce qui signifie} qu'elle s'occupera de tout} du logiciel de provisionnement, de l'application des correctifs, de la sécurité et de} nous aider à faire évoluer automatiquement dynamodb nous permet} de créer des applications qui peuvent fournir pour} des temps de réponse à un chiffre en millisecondes à grande échelle} et pour nos applications critiques,} nous pourrions utiliser la réplication globale pour répliquer nos} ensembles de données dans plusieurs régions} Une catégorie très populaire auprès de mes clients} se trouvent dans des bases de données en mémoire} des bases de données en mémoire} stockeront nos données en mémoire plutôt que sur ceci, qui nous donne alors} des temps de réponse inférieurs à la milliseconde} Et c'est idéal pour les cas d'utilisation} pour stocker les données de session d'un utilisateur} sur} maintenir un classement pour les jeux en ligne ou} former des modèles d'apprentissage automatique} Mais le cas d'utilisation le plus courant que} j'ai vu parmi mes clients est placé} ici sous forme d'argent devant} } nos bases de données relationnelles} Cela nous donnera de bien meilleurs temps de réponse pour nos utilisateurs finaux et atténuera} les pressions de mise à l'échelle de lecture sur la base de données relationnelle sous-jacente} qui peuvent entraîner le verrouillage des ressources} des problèmes de contention et de stabilité, que Makayla vous montrera dans sa démonstration ultérieure pour} en mémoire } Nous avons le choix entre amazon elastic} cache}} C'est un service entièrement géré qui nous permet} de fournir des temps de réponse inférieurs à la milliseconde} et une mise à l'échelle sans interruption} Il est à la fois compatible avec le cache mem}} DM Reedus et les gens l'utilisaient} car le cache mém l'utilisera généralement} pour créer une mise à l'échelle simple } couches cationiques pour} leurs applications sensibles à la latence, alors que nos utilisateurs de Reddit} l'utiliseront pour des cas d'utilisation plus polyvalents, comme pour leurs jeux, leurs analyses en temps réel et leur apprentissage automatique avec regis} Nous avons également le choix d'amazon} Memory Day bay, qui est un cluster entièrement géré avec durabilité} Débat sur la mémoire } nous fournit des performances ultrarapides} et une compatibilité totale avec l'open source regis}, ce qui nous permet ensuite d'utiliser toutes ces structures de données riches, telles que} des ensembles triés pour les classements en ligne en} tirant parti de} Un journal de transactions distribué sur toutes les zones de disponibilité} Memory DB nous fournit une base de données rapide} restauration et redémarrage sans risque de perte de données, ce qui signifie que nous pouvons maintenant} l'utiliser comme base de données principale pour} des ensembles de données persistants} Maintenant que nous comprenons la nécessité} et les avantages d'une architecture de base de données découplée} et que nous avons examiné certains cas d'utilisation} cette base de données spécialement conçue résout} I J'aimerais vous présenter Michaeli} qui a mis tout cela en action} sous la forme d'une démonstration à} Michael} Merci William} Dans cette démo, nous allons regarder} des animaux de compagnie géniaux, des animaux géniaux est une entreprise fictive} et dans ce scénario inventé,} awesome pets est une animalerie en ligne,} awesome pets possède tous } les caractéristiques} d'une boutique de commerce électronique où vous} pouvez parcourir le catalogue, ajouter des articles à} le panier et payer} La pile technologique pour animaux de compagnie est actuellement géniale} composée d'un back-end monolithique et d'un monolithique} Ma base de données de suites} Cette application monolithique alimente toutes les différentes} fonctionnalités et fonctionnalités } Les animaux de compagnie géniaux sont confrontés à un certain nombre de} défis avec leurs monolithes hérités} Tout d'abord, ils ont découvert que certaines requêtes} sont extrêmement lentes, en particulier dans les cas de} charge élevée} Ensuite, à la suite de} chaque requête} de plus en plus lente pendant les pics de trafic,} les demandes des utilisateurs échouent et les utilisateurs sont } Impossible de terminer les transactions} Enfin, la base de données est à court de ressources} et le Seigneur, ce qui peut provoquer le crash de la} base de données et l'indisponibilité de l'application complète} Si vous essayez également de faire évoluer} applications monolithiques} Ces défis peuvent vous sembler très familiers} Alors maintenant je vais vous montrer comment} l'application legacy awesome pets fonctionne en} exécutant un test simple} Ensuite, je vais vous montrer à quel point} les animaux de compagnie peuvent être découplés avec des microservices et} des bases de données spécialement conçues} Comment choisir la bonne base de données pour} le bon travail et vous montrer les} différences de performances entre l'ancienne application monolithique} et application de microservices} Enfin, je vais aborder brièvement certains} des modèles de conception utilisés dans la} nouvelle architecture} Permettez-moi de commencer par vous montrer un} exemple de parcours utilisateur sur des animaux de compagnie géniaux} Comme vous pouvez le voir ici lorsque je} visite des animaux de compagnie}} On me présente le catalogue des animaux de compagnie} Le catalogue montre les types d'animaux de compagnie } disponible} dans le commentaire et le compte pour chaque} type} Je peux ajouter des animaux de compagnie au panier} en cliquant sur le bouton Ajouter au panier} et une fois que j'ai ajouté tous les} animaux de compagnie, je pourrai jeter un œil à} la carte et procéder au paiement} Sur la page de paiement} Je peux saisir toutes les informations requises} pour terminer la transaction et confirmez le} paiement et une fois que le message de confirmation est} affiché, le parcours utilisateur est terminé} Alors lançons le test de charge} pour voir comment fonctionne l'application monolithique} sur le chargement} Il existe de nombreux outils disponibles pour exécuter} des tests de performance tels que j meter ou} artillerie} Pour n'en nommer que quelques-uns} Mais pour cette démo, je } Je vais} utiliser Blaze Meter} Ce test simule un véritable parcours utilisateur} sur des animaux de compagnie géniaux où chaque utilisateur recevra un catalogue d'un article à} le panier et en soumettra un autre} Ce test est configuré avec un total} de 50 utilisateurs simultanés naviguant dans le} parcours pendant une durée de 10 minutes} Et le nombre d'utilisateurs } augmentera progressivement sur une durée d'une} minute} Enfin, ce test se déroulera dans la} région aws Oregon} Je vais maintenant commencer le test de charge} et comme le test prend environ 10} minutes à terminer, je vais accélérer} la vidéo et nous examinerons les résultats une fois le test} terminé} Donc, le test est maintenant complet et} nous pouvons regarder les} résultats sur ces écrans, nous avons deux} graphiques} Celui de gauche montre combien de requêtes ont réussi pendant la durée du test} et combien de demandes ont échoué} Et le graphique de droite affiche} le temps de réponse moyen sur la durée} du test} Si nous nous concentrons sur le graphique sur} le côté droit, nous pouvons voir} qu'à mesure que le nombre d'utilisateurs augmente, le temps de réponse moyen de} l'application ne cesse d'augmenter, atteignant un pic de réponse} temps de réponse d'environ sept secondes} Et à un moment donné, les temps de réponse} ont chuté drastiquement à seulement quelques centaines} de millisecondes Et au bout de quelques minutes,} le temps de réponse remonte à} sept secondes} Si nous regardons le graphique de} à gauche, il est clair pourquoi il y a} une baisse du temps de réponse aux alentours de} 1750} Nous pouvons voir qu'à l'heure actuelle} presque toutes les demandes échouent et} il n'y a aucune demande réussie} Cela nous indique que le site Web était } en panne pendant cette période et} la demande de l'utilisateur} a échoué très rapidement} Donc, allons un peu plus loin pour} voir la cause de ces problèmes ici} J'utilise AWS X ray qui} est un service de suivi pour approfondir} la demande qui a échoué à partir de la carte des services X} ray} Je peux voir mon application monolithique et} les demandes } La couleur rouge ici représente le nombre} de requêtes qui ont échoué dans la} base de données} Donc, je vais maintenant utiliser X} ray insights, AWS x ray insights identifie} où se produisent les problèmes dans les applications,} les enregistrements de chaque problème et} l'impact associé} Et quand j'ouvre un aperçu} Je} peux voir immédiatement quelle est la cause première du problème et son impact}. Dans ce cas, cela me dit} que 23 % de la demande a échoué} dans la base de données} Ensuite, je peux cliquer sur analyser les informations} pour accéder à chaque échec individuel} demande} Une fois que j'ai ouvert une demande qui a échoué, je} peux voir tous les } les composants qui} ont été exécutés pour cette requête, ainsi que} le temps que chacun d'entre eux a pris} Dans ce cas précis, la base de données a renvoyé} une erreur au bout de 17 secondes due à} un blocage} Enfin, examinons les} métriques basées sur les données pour comprendre plus en détail ce qui s'est passé} Si nous nous concentrons sur le processeur } nous pouvons constater que l'utilisation du processeur de la base de données} atteint 100 % très rapidement} et après quelques minutes d'utilisation soutenue} de 100 % du processeur, l'utilisation de l'IP de la base de données} revient à 0 % et puis elle revient à 100 %} C'est parce que la base de données plante et} redémarre en raison d'une utilisation élevée du processeur } Vous pouvez également le valider en examinant} d'autres mesures telles que (right)}} Les opérations et les connexions à la base de données} Comme nous l'avons vu,} cette ancienne application ne fonctionne pas bien, les requêtes peuvent prendre} à 10 secondes pendant les pics de trafic} et la base de données plante} et les pannes de base de données provoquent des pannes (génial) les animaux de compagnie pourraient envisager d'implémenter beaucoup de} optimisations courantes pour les applications monolithiques} Cependant, ils s'attendent à être multipliés par 10} au cours de la prochaine année et ils savent} que même avec des optimisations courantes pour les applications monolithiques}, ils ne seront pas en mesure de} soutenir leur croissance planifiée} C'est pourquoi des animaux de compagnie géniaux ont décidé de} passer à des microservices avec des bases de données spécialement conçues} Essayons donc de comprendre comment ils} décomposent cette application, comment ils ont décidé quelle} base de données utiliser pour chaque cas d'utilisation} dans cette nouvelle architecture, awesome pets est} divisée en quatre microservices, l'ordre d'inventaire} le panier et le catalogue de l'inventaire} Microservice utilise dynamodb} Les données d'inventaire peuvent être stockées dans} un format de valeur clé simple et} il existe un schéma bien défini, tel que} l'ajout ou la suppression d'animaux de compagnie à l'inventaire} Ensuite, nous avons l'ancien traitement} Ce cas d'utilisation nécessite la cohérence des données et} stocke les données dans un format relationnel dénormalisé}} Certains des la logique précédente peut aussi} être réutilisée et c'est pourquoi elle convient parfaitement à une suite} compatible avec amazon aurora} Ensuite, nous avons les microservices de casting} La fonctionnalité de diffusion est la deuxième fonctionnalité la plus utilisée sur des animaux de compagnie géniaux} Elle a un volume élevé de lectures et} d'écritures et les temps de réponse nécessaires devraient} être sept millisecondes, comme vous vous en souvenez peut-être de la session Williams} C'est un excellent cas d'utilisation pour} une base de données en mémoire comme celle de brady's} sur Elastic Cache} Et enfin, nous avons le catalogue, le} catalogue pour le moment, interroge l'intégralité de} l'inventaire disponible et exécute les opérations en fonction du compte} sur le type d'animal de compagnie parce que génial [pets} utilise une base de données relationnelle} Ils ne sont actuellement pas en mesure de fournir} des fonctionnalités de recherche riches et, par conséquent, l'une des technologies qu'ils peuvent utiliser pour} le catalogue est le service amazon (Open Search)}}} La recherche ouverte peut facilement ingérer des recherches et} agréger des milliards de documents} Maintenant que nous avons vu à quoi ressemble l'architecture} cible, lançons un autre test de performance pour voir les performances de la nouvelle} architecture (comme vous pouvez le voir). Je} peux ajouter les paramètres au U} R} L} Pour commencer à utiliser le back-end des microservices} et dans ces microservices,} j'ai à peu près le même nombre d'animaux de compagnie} sinon plus par rapport à l'application monolithique} et les fonctionnalités sont exactement les mêmes} Donc je peux commencer et ouvrir} le test pour mon back-end de microservices} Comme vous pouvez le voir, le test de performance} est identique à la même configuration} que le test précédent et le parcours utilisateur} est le même} Nous obtenons le catalogue, ajout d'une carte} et soumission d'une commande} Et aussi, la configuration est la même} avec 50 utilisateurs au total pour une durée maximale de 10 minutes et avec parmi une} minute d'augmentation} Alors allons-y, lançons ce} nouveau test et examinons} les résultats} Une fois le test terminé} Comme avant, je vais accélérer cette} partie du vidéo jusqu'à la fin du test} Jetons un coup d'œil à ces résultats} En un coup d'œil} Nous pouvons déjà constater que les performances} sont beaucoup plus constantes qu'il n'y a eu aucune erreur lors du test de performance} Et dans l'ensemble, le temps de réponse moyen est} d'environ 160 millisecondes, soit 45 fois} plus rapide que notre } Application monolithique} Jetons donc un coup d'œil au} X et nous pouvons voir} toutes les interactions entre les microservices} Par exemple, nous pouvons voir comment} soumettre toutes les fonctionnalités s'étend réellement sur plusieurs} microservices} Et ici, nous pouvons voir les appels api} pour obtenir le catalogue et ajouter} articles à } le panier} Je peux maintenant regarder des traces spécifiques} pour approfondir une seule demande de commande envoyée} ici, nous pouvons voir le} détail du temps passé} pendant la durée de l'envoi ou} de la transaction} Nous pouvons voir que sous charge} Cette opération n'a pris qu'environ 300 millisecondes,} ce qui est 25 fois plus rapide que} se soumettent à la fonctionnalité de l'application monolithique} dans les mêmes conditions. Dans la démo}, nous avons vu comment l'architecture des microservices} est capable de bien évoluer pour faire face} au trafic et fournir une réponse cohérente} temps} Une autre caractéristique de cette nouvelle architecture est} qu'elle peut accomplir beaucoup une plus grande disponibilité} Si l'une des bases de données tombe en panne,} un seul des microservices est affecté et} l'application peut encore fonctionner partiellement en} passant aux microservices} Non seulement nous pouvons évoluer et fonctionner} mieux, mais nous obtenons également une plus grande disponibilité} Enfin, j'aimerais mentionner brièvement} la conception modèles qui ont été utilisés dans cette} composition} Le premier est la notification des événements dans cette} nouvelle architecture} Le microservice du catalogue doit être} mis à jour chaque fois qu'un élément est ajouté} ou retiré de l'inventaire} Pour implémenter ce modèle, nous utilisons les flux dynamodb}, qui est une fonctionnalité de dynamodb} qui vous permet de diffuser chaque modification} sur la table} Le deuxième modèle est le modèle saga} Ce modèle nous permet d'exécuter des transactions commerciales sur plusieurs microservices} Dans cet exemple, le modèle de cycle a été} implémenté à l'aide des fonctions d'étape AWS et la} transaction couvre l'inventaire, la commande et} the cat microservices} Si vous souhaitez en savoir plus} sur les modèles de microservices} Je vous recommande de regarder la session intitulée build} Microservices brésiliens utilisant des modèles tolérants aux pannes dans} cette session, nous avons examiné quelles sont} les exigences des applications modernes d'aujourd'hui} Nous avons ensuite exploré pourquoi les clients sont passés de} a } Nous avons examiné comment vous pouvez choisir} la bonne base de données pour le bon travail} et nous avons vu comment elle peut vous aider} à atteindre une plus grande échelle, de meilleures performances et} une plus grande disponibilité} Nous avons abordé un certain nombre de sujets différents} au cours de cette session, mais l'apprentissage ne le fait pas vous devez vous arrêter ici} Nous vous encourageons à consulter notre} contenu de formation et de certification} Nous proposons plus de 500 cours numériques gratuits} qui peuvent vous aider, vous et votre équipe, à acquérir de nouvelles compétences en matière de cloud et à découvrir} les derniers services} Et au fur et à mesure que vous développez vos compétences, pensez à} vous préparer à l'une de nos 11 certifications} Vous pouvez scanner les codes QR dans} cette diapositive pour en savoir plus} Merci d'avoir participé à cette conférence} Nous aimerions connaître vos commentaires} pour nous aider à améliorer le sommet AWS} Expérience} Alors, n'oubliez pas de terminer la session} Enquête} Merci Bonjour et bienvenue à choisir} la bonne base de données pour les applications modernes car } fait partie de notre série West Summit en ligne}} Je m'appelle William Wong et je suis} un architecte spécialisé en solutions de bases de données} Et aujourd'hui je serai rejoint par Michael} Riccardi, qui est notre architecte spécialisé en solutions de développement} Aujourd'hui} Nous sommes vraiment ravis d'être ici pour} vous montrer comment les bases de données spécialement conçues peuvent} être utilisé pour améliorer l'échelle, les performances et la disponibilité de vos applications.} pour notre} agenda, vous trouverez une introduction aux} exigences des applications modernes} Nous examinerons ensuite les défis qui} sont résolus à l'aide de microservices et de bases de données spécialement conçues} Avant de voir comment nous pouvons} nous y prendre choisir les bonnes bases de données} pour vos charges de travail particulières} Michael} Nous allons ensuite approfondir} où il modernisera une application, passant d'une pile de bases de données relationnelles monolithiques à une pile de bases de données relationnelle monolithique à celle de} utilisant des bases de données spécialement conçues et vous montrera} les différences en termes de performances et d'échelle} Alors commençons et examinons } les exigences de nos applications modernes} Et nous examinons d'abord les applications} que nous utilisons tous les jours, comme} notre covoiturage, les médias, le streaming, les services bancaires, les jeux} et les réseaux sociaux} Nous commençons à voir des modèles communs} Ces modèles peuvent être des millions d'utilisateurs} accédant à nos applications dans différentes zones géographiques} Et ces mêmes utilisateurs s'attendent à des expériences instantanées} qui pourraient se résumer à des temps de réponse constants de la milliseconde, voire de l'ordre de la milliseconde.} Nos applications devront être hyperdimensionnées} pour répondre aux demandes d'événements tels que} nos ventes flash ou le traitement de l'urine, et} puis redimensionner} Nous ne sommes pas utilisés, donc} pouvons } Il est prévu de capturer plus} de données au cours des trois prochaines années que} celles des 30 dernières années} Et cela nécessitera des outils spécialisés pour} traiter les pétaoctets} Si ce n'est pas zéro octet de données structurées} et non structurées} Si nous prenons du temps maintenant et} réfléchissons aux modèles architecturaux de la plupart} de ces applications de base cloud, vous constaterez} que ce sont toutes des microservices} Cela signifie qu'elles sont hautement distribuées, faiblement} couplées et accessibles via un P} I} S} Alors, que signifie ce changement d'architecture} pour notre base de données sous-jacente.} Nos} applications sont maintenant découplées en services} Cela permet chacune de ces des services pour} avoir sa propre base de données indépendante} Et cela nous apportera de nombreux} avantages, par exemple, nous donnera la possibilité d'hyperdimensionner nos applications car} chaque service et canal de base de données évolue indépendamment} Prenons le Black Friday comme une utilisation} cas} Nous pourrions avoir besoin de dimensionner notre catalogue} et le paiement service à des centaines de milliers} de demandes simultanées sur une courte période} mais nos inscriptions d'utilisateurs peuvent ne pas augmenter dans la même mesure} Un autre avantage est l'agilité supplémentaire} Puisque nous pouvons désormais innover plus rapidement sur} différents composants} Nous pouvons rapidement tester et annuler} de nouvelles versions et fonctionnalités sur un } modulaire} (sans gérer toutes les dépendances complexes) couplées qui sont liées aux monolithes} Un défi commercial courant consiste à rendre nos} applications plus disponibles et, en découplant nos} bases de données, cela augmentera leur disponibilité globale} puisque nous n'avons plus de base de données monolithique} qui fait office de } point de discorde pour nos événements tels que} des déploiements de code, des mises à niveau et des correctifs} Maintenant que nous comprenons les avantages} du découplage de nos données} T pourquoi envisagerions-nous des bases de données spécialement conçues pour nos microservices} Nos développeurs veulent la bonne base de données pour} répondre aux besoins de notre {applications} comme nous l'avons décrit précédemment} Et franchement, cette approche unique qui consiste à utiliser une base de données relationnelle pour} tout, ne fonctionne tout simplement plus}} Par exemple, nous pouvons avoir besoin d'une base de données} pour fournir des temps de réponse de latence de l'ordre de la microseconde (afin} que nous puissions afficher rapidement nos sites Web} ou pour fournir des services cohérents des temps de réponse pour} répondre aux demandes des utilisateurs d'un chirurgien} Et l'architecture relationnelle n'est pas la meilleure solution pour ces cas d'utilisation particuliers} En fait, ne pas utiliser la bonne} base de données entraînera généralement des problèmes de performance,} un manque d'évolutivité, un manque de flexibilité pour les développeurs} et une augmentation de notre } Donc, traditionnellement, lorsque je parle à mes} clients, un obstacle à l'adoption de ces objectifs} des bases de données créées avec des frais généraux opérationnels potentiels} Et cela incluait des investissements dans du matériel initial et des logiciels ou de l'expertise pour les rendre évolutives, hautement disponibles et performantes} Et c'est là qu'AWS entre en jeu.} } Nous proposerons le portefeuille le plus large et le plus complet} de plus de 15 bases de données spécialisées qui} peuvent prendre en charge les différents modèles de données en} tirant parti de bases de données personnalisées et entièrement gérées} que nous avons créées de A à Z} les clients peuvent désormais gagner du temps et de l'argent,} améliorer les performances à grande échelle et innover plus rapidement} Nous avons des bases de données spécialement conçues pour correspondre à} tous les cas d'utilisation (valeur clé relationnelle,} document en mémoire, séries chronologiques à colonnes larges}, registre et nos bases de données graphiques} Donc, maintenant que nous avons compris le besoin} de bases de données spécialement conçues, comment pourriez-vous sélectionner les bonnes bases de données} pour votre usage particulier} cas} Ce que j'aimerais dire aux gens, c'est :} au lieu de regarder une liste de} 100 bases de données différentes, pourquoi ne pas commencer} par réfléchir aux catégories de bases de données courantes} Alors maintenant, nous examinons rapidement les} catégories} Non seulement vous trouverez cette base de données relationnelle familière sur la gauche, mais} vous allez aussi voir d'autres bases de données, des bases de données comme} notre base de données de documents Amazon qui est optimisée} pour stocker les données au format Jason} Et comme il s'agit d'une base de données sans suite,} cela nous donnera cette flexibilité} en ce qui concerne} la modification des schémas d'applications mais elle nous permettra aussi} d'interroger des documents en fonction de} n'importe quel attribut} Et c'est vraiment pratique pour notre} gestion de contenu ou applications mobiles ou une} base de données graphique comme amazon Neptune, qui} nous permet ensuite de travailler avec} des ensembles de données hautement connectés} Nous pouvons essayer de modéliser cela} dans une base de données relationnelle avec des articulations compliquées} et des requêtes imbriquées mais notre latence est} augmentera au fur et à mesure que le nombre de nos} les relations augmentent dans les bases de données graphiques} Cependant, cela nous permet de parcourir des millions} de relations en quelques secondes, ce qui est excellent} pour la détection des fraudes, les réseaux sociaux et nos} moteurs de recommandation} Enfin, comme une base de données de séries chronologiques} comme notre flux temporel amazon qui est} optimisé pour ingérer des milliards de } séquence temporelle} données par jour et} nous donner} des fonctions basées sur le temps telles que la corrélation} et l'interpolation afin que nous puissions obtenir} de meilleures informations à partir de ces données} Et c'est excellent pour notre IoT} Devops ou applications de suivi d'événements} Prenons le temps de plonger} un peu plus loin dans certaines catégories très courantes} que je Je l'ai vu parmi mes clients} Commençons par un modèle de données relationnel très familier}, les données relationnelles sont hautement} structurées et les données sont divisées en tableaux et les relations appliquées par} le système sont des clés primaires et référentielles} et les bons cas d'utilisation pour celles-ci seront} des charges de travail pour lesquelles nous ne pouvons pas (tous prédéfinis)} nos modèles d'accès à l'avance ou si} nous avions des applications nécessitant un référentiel élevé} intégrité et forte cohérence} Comme pour nos systèmes de paiement en ligne} Une base de données native dans le cloud que nous pourrions choisir} pour nos modèles relationnels est amazon Arora} Arora est compatible à la fois avec ma suite} et Postgres et peut } aidez-nous à améliorer} nos performances en fournissant jusqu'à cinq} fois plus de débit que celui de la version standard} Ma suite et trois fois plus que} celle de Postgres standard} Cela nous aidera à faire évoluer automatiquement les ressources de calcul et de stockage et nous avons dessiné} billy stockez nos données de six manières dans} trois zones de disponibilité } Et comme il s'agit d'un service géré,} il assurera l'automatisation de tâches telles que} le déploiement et le provisionnement,} des correctifs et des mises à niveau réguliers,} des sauvegardes et nous offrira des fonctionnalités de sécurité telles que} le cryptage en transit et au repos} Une autre catégorie intéressante} Pour examiner notre valeur clé} bases de données} Les données de valeur clé sont celles qui utilise} cette méthode clé-valeur simple pour stocker} et récupérer des données, et sa force réside} dans sa conception qui consiste à partitionner fortement les données (ou} à les partager physiquement, puis à les stocker physiquement) en fonction de cette clé de partition} Cette conception lui permet de s'adapter horizontalement à pratiquement n'importe quelle taille tout en nous offrant} des temps de réponse cohérents , quelle que soit l'échelle} Passons donc à un cas d'utilisation} pour un jeu en ligne qui doit} stocker les données de session d'un utilisateur et possède} un modèle d'accès défini via le gamer tag} pour récupérer cet ensemble de données} Puisqu'il s'agit d'un jeu en ligne, nous voulons} garantir une expérience cohérente au joueur, peu importe si } il y avait} 10 ou même 100 000 utilisateurs} Si le jeu prend son envol dans ce} cas d'utilisation particulier, nous utiliserons une base de données clé} valeurs pour obtenir des temps de réponse cohérents,} indépendamment de la croissance de l'application} Une base de données spécialement conçue que nous pourrions choisir} pour nos bases de données de valeurs clés est amazon} dynamodb} Elle est géré et sans serveur, ce qui signifie} qu'il s'occupera de tout} du logiciel de provisionnement, de l'application des correctifs, de la sécurité et} de nous aider à faire évoluer automatiquement dynamodb nous permet} de créer des applications capables de fournir} des temps de réponse à un chiffre en millisecondes à grande échelle} et pour nos applications critiques, nous pourrions utiliser } réplication pour répliquer nos} ensembles de données dans plusieurs régions} Une catégorie très populaire parmi mes clients} concerne les bases de données en mémoire} Les bases de données en mémoire} stockeront nos données en mémoire plutôt que sur celle-ci, ce qui nous donne} des temps de réponse inférieurs à la milliseconde} Et c'est idéal pour les cas d'utilisation} pour stocker un utilisateur données de session sur} le maintien d'un classement pour les jeux en ligne ou} la formation de modèles d'apprentissage automatique} Mais le cas d'utilisation le plus courant que} j'ai vu parmi mes clients est placé} ici sous forme d'argent devant} nos bases de données relationnelles} Cela nous donnera une bien meilleure réponse} temps de réponse pour nos utilisateurs finaux et allège} lire des pressions d'échelle sur la base de données relationnelle sous-jacente} qui peuvent entraîner des problèmes de blocage des ressources} de conflit et de stabilité, que Makayla va} vous montrer dans sa démonstration suivante pour} dans les bases de données en mémoire} Nous avons le choix entre amazon elastic} cache} C'est un service entièrement géré qui nous permet} de fournir pour des temps de réponse inférieurs à la milliseconde} et une mise à l'échelle sans interruption} Il est à la fois compatible avec le cache mem}}} DM Reedus et les gens l'utilisaient} car le cache mem l'utilisera généralement} pour créer des couches de cations de mise à l'échelle simples pour} leurs applications sensibles à la latence, tandis que nos utilisateurs de Reddit} l'utiliseront pour une utilisation plus polyvalente} des cas comme pour leurs jeux} en temps réel}, leurs analyses en temps réel et leur apprentissage automatique avec regis} Nous avons également le choix d'amazon} Memory Day bay, qui est un cluster entièrement géré et durable} Le débat sur la mémoire nous fournit des performances ultrarapides} avec une compatibilité totale avec l'open source regis} qui nous permet ensuite d'utiliser } toutes ces structures de données sont riches, telles que} des ensembles triés pour les classements en ligne en} tirant parti de} Un journal des transactions distribué entre les zones de disponibilité} La base de données mémoire nous fournit une base de données rapide} une restauration et des redémarrages sans risque de perte de données, ce qui signifie que nous pouvons maintenant} l'utiliser comme base de données principale pour } ensembles de données persistants} Maintenant que nous avons compris la nécessité} et les avantages d'une architecture de base de données découplée} et que nous avons examiné quelques cas d'utilisation} que des bases de données spécialement conçues peuvent résoudre} J'aimerais vous présenter Michaeli} qui a mis tout cela en action sous la forme d'une démonstration à} Michael} Merci William} Dans cette démo, nous allons regarder} awesome pets, awesome pets est une entreprise fictive} et dans ce scénario inventé,} awesome pets est une animalerie en ligne,} awesome pets possède toutes les caractéristiques} d'une boutique de commerce électronique où vous} pouvez parcourir le catalogue, ajouter des articles au panier et vérifier out current awesome} La pile technologique pour animaux de compagnie se compose d'un héritage} d'un backend monolithique et d'un monolithique} Ma base de données de suites} Cette application monolithique alimente toutes les caractéristiques et fonctionnalités de géniaux animaux de compagnie} Des animaux de compagnie géniaux sont confrontés à un certain nombre de} défis avec leurs monolithes hérités} Tout d'abord, ils ont a découvert que certaines requêtes} sont extrêmement lentes, en particulier dans les cas de} charge élevée} Ensuite, à la suite de chaque requête} de plus en plus lente pendant les pics de trafic,} les demandes des utilisateurs échouent et les utilisateurs sont} incapables de terminer les transactions} Enfin, la base de données est à court de ressources} et le Seigneur qui peut provoquer } la base de données tombe en panne et l'application complète} est indisponible} Si vous essayez également de faire évoluer} applications monolithiques} Ces défis peuvent vous sembler très familiers} Alors maintenant je vais vous montrer comment} l'ancienne application géniale pour animaux de compagnie fonctionne en effectuant un test simple} Ensuite, je vais vous montrer à quel point c'est génial} les animaux de compagnie peuvent être découplés avec des microservices et} des bases de données spécialement conçues} Comment choisir la bonne base de données pour} le bon travail et vous montrer les} différences de performances entre l'ancienne application monolithique} et l'application de microservices} Enfin, je vais aborder brièvement certains} des modèles de conception utilisés dans } nouvelle architecture} Permettez-moi de commencer par vous montrer un} exemple de parcours utilisateur sur des animaux de compagnie géniaux} Comme vous pouvez le voir ici lorsque} je visite des animaux géniaux} On me présente le catalogue des animaux de compagnie} Le catalogue montre les types d'animaux disponibles} dans le commentaire et compte pour chaque} type} Je peux ajouter des animaux de compagnie au panier} en cliquant sur le bouton Ajouter à } et une fois que j'ai ajouté tous les} animaux de compagnie, je pourrai regarder} la carte et procéder au paiement} Sur la page de paiement} Je peux saisir toutes les informations requises} pour terminer la transaction et confirmer le} paiement et une fois que le message de confirmation est} affiché, le parcours utilisateur est terminé} Alors allons-y le test de charge} pour voir les performances de l'application monolithique} sur la charge} Il existe de nombreux outils disponibles pour exécuter} des tests de performance tels que j meter ou} artillerie} Pour n'en nommer que quelques-uns} Mais pour cette démo, je vais} utiliser Blaze Meter} Ce test simule un véritable parcours utilisateur} sur des animaux de compagnie géniaux où chaque utilisateur obtiendra} un cataloguer un article à} le panier et en soumettre un autre} Ce test est configuré avec un total} de 50 utilisateurs simultanés naviguant dans le} trajet pendant une durée de 10 minutes} Et le nombre d'utilisateurs augmentera} progressivement sur une durée d'une} minute} Enfin, ce test se déroulera dans la} région aws Oregon} I va maintenant commencer le test de charge} et comme le test prend environ 10} minutes, je vais accélérer} la vidéo et nous examinerons les résultats une fois le test} terminé} Donc le test est maintenant terminé et} nous pouvons regarder les} résultats sur ces écrans, nous avons deux} graphiques} Celui de gauche montre } combien de requêtes ont réussi pendant la durée du test} et combien de demandes ont échoué} Et le graphique de droite affiche} le temps de réponse moyen sur la durée} du test} Si nous nous concentrons sur le graphique sur} le côté droit, nous pouvons voir} que lorsque le nombre d'utilisateurs augmente}, le temps de réponse moyen de} l'application ne cesse d'augmenter, atteignant un pic de réponse} temps d'environ sept secondes} Et à un moment donné, les temps de réponse} ont chuté drastiquement à seulement quelques centaines} de millisecondes Et au bout de quelques minutes,} le temps de réponse remonte à} sept secondes} Si nous regardons le graphique de} à gauche, c'est clair pourquoi il y a} une baisse du temps de réponse aux alentours de} 1750} Nous pouvons constater qu'à ce stade} presque toutes les demandes échouent et} il n'y a aucune demande réussie} Cela nous indique que le site Web était en panne pendant cette période et que la demande de l'utilisateur} a échoué très rapidement} Alors allons un peu plus loin pour} voir ce qui est } à l'origine de ces problèmes} J'utilise AWS {X} ray, qui est un service de suivi pour approfondir} la demande qui a échoué à partir de la carte du service X} ray} Je peux voir mon application monolithique et} les requêtes envoyées à la base de données} La couleur rouge représente ici le nombre} de demandes qui ont échoué dans la} base de données} Donc Je vais maintenant utiliser X} ray insights, AWS x ray insights identifie} où se produisent les problèmes dans les applications,} les enregistrements de chaque problème et} l'impact associé} Et quand j'ouvre un aperçu, je} peux voir immédiatement quelle est la cause première du problème et l'impact} qu'il a. Dans ce cas, c'est révélateur } moi que 23 % de la demande a échoué} dans la base de données} Ensuite, je peux cliquer sur Analyser les informations} pour accéder à chaque échec individuel} demande} Une fois que j'ai ouvert une demande qui a échoué, je} peux voir tous les composants qui} ont été exécutés pour cette demande ainsi que} combien de temps chacun d'entre eux a pris} Dans ce cas précis, } la base de données a renvoyé} une erreur après 17 secondes à cause de} un blocage} Enfin, examinons les} métriques basées sur les données pour comprendre plus} en détail ce qui s'est passé} Si nous nous concentrons sur l'utilisation du processeur,} nous pouvons constater que l'utilisation du processeur de la base de données} grimpe à 100 % très rapidement} et après quelques minutes de [soutenu} Utilisation du processeur à 100 %, l'utilisation de l'adresse IP de la base de données} revient à 0 % Et puis elle revient à 100 %} C'est parce que la base de données plante et} redémarre en raison d'une utilisation élevée du processeur} Vous pouvez également le valider en examinant} d'autres mesures telles que right I} Ops et connexions à la base de données} Comme nous l'avons vu } cette application héritée ne fonctionne pas bien, les requêtes peuvent prendre jusqu'à 10 secondes pendant les pics de trafic} et la base de données plante, provoquant des pannes (génial)} Les animaux de compagnie pourraient envisager de mettre en œuvre bon nombre de} l'optimisation courante pour les applications monolithiques} Cependant, ils s'attendent à une croissance 10 fois} au cours de la prochaine année et ils savent} que même avec les optimisations courantes pour les applications monolithiques, ils ne seront pas en mesure de} soutenir leur croissance planifiée} C'est pourquoi des animaux de compagnie géniaux ont décidé de} passer à des microservices avec des bases de données spécialement conçues} Essayons donc de comprendre comment ils} décomposent cette application, comment ils ont décidé } quelle base de données utiliser pour chaque cas d'utilisation} Dans cette nouvelle architecture, awesome pets est} divisée en quatre microservices, la commande d'inventaire} le panier et le catalogue de l'inventaire} Le microservice utilise dynamodb} Les données d'inventaire peuvent être stockées dans} un format de valeur clé simple et il existe} un modèle bien défini tel que} ajout ou suppression d'animaux de compagnie à l'inventaire} Ensuite, nous avons l'ancien traitement} Ce cas d'utilisation nécessite la cohérence des données et} stocke les données dans un format relationnel dénormalisé}} Certaines des logiques précédentes peuvent également} être réutilisées et c'est pourquoi il convient parfaitement à une suite} compatible amazon aurora} Ensuite, nous avons le cast (microservices)} La fonctionnalité cast est la deuxième fonctionnalité la plus utilisée sur des animaux de compagnie géniaux} Elle a un volume élevé de lectures et} d'écritures et les temps de réponse nécessaires devraient} être de sept millisecondes, comme vous pouvez vous en souvenir de la session Williams} C'est un excellent cas d'utilisation pour} une base de données en mémoire telle que celle de brady } sur Elastic Cache} Et enfin, nous avons le catalogue, le} catalogue pour le moment, interroge l'intégralité de} l'inventaire disponible et exécute le compte en fonction du type d'animal de compagnie} parce que awesome pets} utilise une base de données relationnelle} Ils ne sont actuellement pas en mesure de fournir} une fonctionnalité de recherche riche et donc l'un des} technologies pour lesquelles ils peuvent utiliser} le catalogue est le service amazon (Open Search})}} La recherche ouverte peut facilement ingérer des recherches et} agréger des milliards de documents} Maintenant que nous avons vu à quoi ressemble l'architecture cible, lançons un autre test de performance pour voir comment la nouvelle architecture fonctionne comme vous le pouvez voir} Je} peux ajouter les paramètres à l'U} R} L} Pour commencer à utiliser le back-end des microservices} et dans ces microservices, j'ai à peu près le même nombre d'animaux de compagnie} sinon plus par rapport à l'application monolithique} et la fonctionnalité est exactement la même}} Donc je peux aller de l'avant et ouvrir} le test pour mon } microservices}} Comme vous pouvez le constater, le test de performance} est identique à la même configuration} que le test précédent et} le parcours utilisateur est le même}} Nous obtenons le catalogue, ajoutons une carte} et soumettons une commande} Et la configuration est la même} avec 50 utilisateurs au total pour une durée maximale de 10 minutes et avec entre une} minute d'accélération} Alors allons-y et lançons ce} nouveau test et regardons} les résultats} Une fois le test terminé} Comme avant, je vais accélérer cette} partie de la vidéo jusqu'à la fin du test} Jetons un coup d'œil à ces résultats} en un coup d'œil} Nous pouvons déjà voir que la performance} est énorme plus cohérent qu'il n'y a pas eu d'erreur lors du test de performance} Et dans l'ensemble, le temps de réponse moyen est} d'environ 160 millisecondes, soit 45 fois} plus rapide que notre application monolithique} Alors jetons un coup d'œil au} X ray et nous pouvons voir ici} toutes les interactions entre les microservices} Pour exemple, nous pouvons voir comment {{soumettre toutes les fonctionnalités} couvre réellement plusieurs} microservices} Et ici, nous pouvons voir les {api} appels} pour obtenir le catalogue et ajouter} articles au panier} Je peux maintenant regarder des traces spécifiques} pour approfondir une seule demande de commande (envoi}) ici, nous pouvons voir la répartition des le temps a été passé} pendant la durée de l'envoi ou} de la transaction} Nous pouvons voir que sous charge} Cette opération n'a pris qu'environ 300 millisecondes,} soit 25 fois plus rapide que la} soumission à la fonctionnalité de l'application monolithique} dans les mêmes conditions dans la démo}, nous avons vu comment les microservices } architecture} est capable de bien évoluer pour faire face} au trafic et fournir une réponse cohérente} temps} Une autre caractéristique de cette nouvelle architecture est} qu'elle peut atteindre une disponibilité beaucoup plus grande} Si l'une des bases de données tombe en panne,} un seul des microservices est affecté et} l'application peut partiellement immobiliser function by} passage aux microservices} Non seulement nous pouvons évoluer et être plus performants} mieux, mais nous obtenons également une plus grande disponibilité} Enfin, j'aimerais mentionner brièvement} les modèles de conception qui ont été utilisés dans cette} composition} Le premier est la notification des événements dans cette} nouvelle architecture} Le microservice du catalogue doit être} (mis à jour chaque fois qu'un article est ajouté} ou retiré de l'inventaire} Pour implémenter ce modèle, nous utilisons les flux dynamodb}, qui est une fonctionnalité de dynamodb} qui vous permet de diffuser chaque modification} sur la table} Le deuxième modèle est le modèle saga} Ce modèle nous permet d'exécuter des transactions commerciales} dans plusieurs microservices} Dans cet exemple, le modèle de cycle a été} implémenté à l'aide des fonctions d'étape d'AWS et la} transaction couvre l'inventaire, la commande et} les microservices cat} Si vous souhaitez en savoir plus} sur les modèles de microservices} Je vous recommande de regarder la session intitulée build} Brazilian des microservices utilisant des modèles tolérants aux pannes} dans} cette session, nous avons examiné quelles sont} les exigences des applications modernes d'aujourd'hui} Nous avons ensuite exploré pourquoi les clients sont passés d'une approche universelle à} des bases de données spécialement conçues} Nous avons examiné comment vous pouvez choisir} la bonne base de données pour le bon travail} et nous avons vu comment cela peut vous aider} à atteindre une plus grande échelle, de meilleures performances et} une plus grande disponibilité} Nous avons abordé un certain nombre de sujets différents} dans cette session, mais l'apprentissage ne doit pas s'arrêter là} Nous vous encourageons à consulter notre} contenu de formation et de certification} Nous proposons plus de 500 cours numériques gratuits} qui peuvent vous aider, vous et votre équipe} à acquérir de nouvelles compétences en matière de cloud et à découvrir} les derniers services} Et au fur et à mesure que vous développez vos compétences, pensez à} vous préparer à l'une de nos 11 certifications} Vous pouvez scanner les codes QR dans} cette diapositive pour en savoir plus} Merci d'avoir participé à cette conférence} Nous aimerions connaître vos commentaires} pour vous aider } nous améliorons le sommet AWS}} L'expérience} N'oubliez donc pas de répondre à la session} enquête}